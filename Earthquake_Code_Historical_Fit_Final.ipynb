{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Test the Critical Point Theory on Historical Data\n",
    "\n",
    "This code was used to produce the results in sections 4.1 and 4.2.\n",
    "\n",
    "1. Select a major earthquake and identify the time, epicenter location and magnitude\n",
    "\n",
    "2. Select all earlier earthquakes in a circle of set radius around the epicenter\n",
    "\n",
    "3. Exclude any earthquakes with a magnitude less than 2 points lower than the major earthquake magnitude\n",
    "\n",
    "4. Calculate the cumulative Benioff strain for these earthquakes\n",
    "\n",
    "5. Fit the data with a straight-line a power-law and a power-law with log-periodic oscillations\n",
    "\n",
    "    (a) For a power-law fit the parameters m and B and use the values from the major earthquake for A (final cumulative Benioff strain) and t_{f} (time of the final earthquake)\n",
    "\n",
    "    (b) The parameter m was restricted to be between 0 and 0.8 to ensure accelerating seismicity and the parameter B was restricted to be negative\n",
    "\n",
    "    (c) The fitting was only carried out if there were at least 10 pre-cursor earthquakes\n",
    "\n",
    "6. Calculate the RMSE for each fit and the ratio of a power-law to the straight-line RMSE values\n",
    "\n",
    "7. Repeat for circles of increasing size (from 10 km up to 1300 km)\n",
    "\n",
    "8. Find the radius with the smallest ratio i.e the one where a power-law fit is the best compared to the straight-line fit â€“ this is the size of the critical region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt, pi\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import shapely.geometry\n",
    "import pyproj\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data - ANSS earthquake catalogue\n",
    "df = pd.read_csv(\"Data/ANSS_catalogue.csv\", encoding = 'latin')\n",
    "print(df.shape)\n",
    "\n",
    "#Convert the date to datetime and check the range\n",
    "df.Date = pd.to_datetime(df.Date, format = '%d/%m/%Y')\n",
    "print(df.Date.min())\n",
    "print(df.Date.max())\n",
    "\n",
    "#Add columns for the year, years since 1900 and days since 1900\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['year_1900'] = df['year'] - 1900\n",
    "df['day_1900'] = df['year_1900']*365 + df['Date'].dt.day\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the dataset by magnitude\n",
    "df.sort_values(['Magnitude'], ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Remove aftershocks (rough method)\n",
    "If more than one earthquake occurs on the same day\n",
    "in the same approximate location keep only the largest earthquake\n",
    "'''\n",
    "df['lat_round'] = round(df.Latitude,0)\n",
    "df['long_round'] = round(df.Longitude,0)\n",
    "df['Date_round'] = df.year.map(str) + df['Date'].dt.week.map(str)\n",
    "df.drop_duplicates(['Date_round','lat_round','long_round'],inplace = True)\n",
    "df.drop(['lat_round','long_round', 'Date_round'], axis = 1, inplace = True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the energy release in Nm\n",
    "df['Energy_log10'] = 4.8 + 1.5*df['Magnitude']\n",
    "df['Energy'] = 10 ** df.Energy_log10\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the critical radius (from Jaume and Sykes 1999)\n",
    "df['R_log10'] = -0.2 + 0.36*df['Magnitude']\n",
    "df['R_km'] = 10 ** df.R_log10\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop some columns\n",
    "df.drop(['Time','Depth','NbStations','Gap','Distance','RMS','Source','EventID'], axis = 1, inplace = True)\n",
    "\n",
    "#Convert latlong from degrees to radians\n",
    "df['lat_rad'] = (df.Latitude*pi)/180\n",
    "df['lon_rad'] = (df.Longitude*pi)/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the key earthquakes from the supporting papers\n",
    "key_earthquakes = df[~df.Paper.isna()]\n",
    "key_earthquakes = key_earthquakes[~key_earthquakes.Name.isna()]\n",
    "print(key_earthquakes.shape)\n",
    "key_earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A function to calculate the great circle distance between two points \n",
    "on the earth (specified in radians)\n",
    "This function was taken from the internet\n",
    "\"\"\"\n",
    "def haversine(target_lon, target_lat, all_lon, all_lat): \n",
    "    dlon = all_lon - target_lon \n",
    "    dlat = all_lat - target_lat \n",
    "    # haversine formula\n",
    "    a = np.sin(dlat/2)**2 + np.cos(target_lat) * np.cos(all_lat) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371 # Radius of earth in km. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Function to return all earthquakes within a radius of a target point\n",
    "and with magnitude greater than M_min\n",
    "\"\"\"\n",
    "def get_points(target_point, all_points, radius = 100, M_min = 4):\n",
    "        \n",
    "    #Filter to only earthquakes over the set magnitude\n",
    "    all_points = all_points[all_points.Magnitude >= M_min]   \n",
    "    \n",
    "    #Filter to only records before the date of the target point (and the target point itself)\n",
    "    all_points = all_points[all_points.Date <= target_point.Date]\n",
    "    #print(\"Number of earlier earthquakes: %d\"  % all_points.shape[0])\n",
    "    \n",
    "    #Calculate the distance between the target point and all other points\n",
    "    all_points['distance'] = haversine(target_point.lon_rad,target_point.lat_rad,\n",
    "                                       all_points.lon_rad, all_points.lat_rad)\n",
    "    \n",
    "    #Filter to only points within the radius\n",
    "    all_points = all_points[all_points['distance'] <= radius]\n",
    "    #print(\"Number of earlier earthquakes within %d km: %d\"  % (radius, all_points.shape[0]))\n",
    "    \n",
    "    #Calculate the time delta in days\n",
    "    all_points['Time_Delta'] = (target_point.Date - all_points.Date).dt.days\n",
    "    \n",
    "    #Return the filtered dataset of earthquakes\n",
    "    return(all_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to order a table of earthquakes by date \n",
    "and calculate their cummulative Benioff strain\n",
    "\"\"\"\n",
    "def benioff_calc(all_points):\n",
    "    #Sort the earthquakes by date\n",
    "    all_points.sort_values('Date', inplace = True)\n",
    "    \n",
    "    #Calculate the cummulative Benioff strain\n",
    "    all_points['Energy_sqrt'] = np.sqrt(all_points.Energy)\n",
    "    all_points['Cummulative_Benioff_Strain'] = all_points['Energy_sqrt'].cumsum()\n",
    "    \n",
    "    #Return the original dataset with a new column for the cummulative Benioff strain\n",
    "    return(all_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to calculate the rmse for predictions\n",
    "\"\"\"\n",
    "def rmse_calc(pred, all_points):\n",
    "    #Calculate rmse\n",
    "    err = all_points.Cummulative_Benioff_Strain - pred\n",
    "    err_squared = err**2\n",
    "    mean_err = np.mean(err_squared)\n",
    "    rmse = np.sqrt(mean_err)\n",
    "    #Return the rmse\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Fitting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to fit a straight-line to data\n",
    "\"\"\"\n",
    "def straight_line_fit(all_points, final_benioff):\n",
    "    #Define the straight line function and parameters\n",
    "    def straightLine(x, A, B):\n",
    "        return A + B*x\n",
    "    \n",
    "    #Fit the data\n",
    "    popt, pcov = curve_fit(straightLine, all_points.day_1900, all_points.Cummulative_Benioff_Strain)\n",
    "    #Make predictions\n",
    "    pred = popt[0] + popt[1]*all_points.day_1900\n",
    "    #Calculate the rmse\n",
    "    rmse = rmse_calc(pred, all_points) \n",
    "    return(popt, rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to fit a power-law to data\n",
    "\"\"\"\n",
    "def power_law_fit(all_points, final_benioff, final_t):\n",
    "    #Define the power-law function and parameters\n",
    "    #Note that the parameters A and tf are fixed (taken from the major earthquake)\n",
    "    def power_law(x, B, m):\n",
    "        return B*x**m\n",
    "\n",
    "    #Set a starting point for the parameter search\n",
    "    starting_point = [-1000000, 0.3]\n",
    "    #Fit the data\n",
    "    popt, pcov = curve_fit(power_law,\n",
    "                           final_t - all_points.day_1900, #x\n",
    "                           all_points.Cummulative_Benioff_Strain - final_benioff,\n",
    "                           p0 = starting_point,\n",
    "                           maxfev = 10000,\n",
    "                           bounds=([-np.inf,0], [np.inf,0.8]) #Set bounds on B and m\n",
    "                          )\n",
    "    #Make the predictions\n",
    "    pred = final_benioff + popt[0]*(final_t - all_points.day_1900)**popt[1]\n",
    "    #Calculate the rmse\n",
    "    rmse = rmse_calc(pred, all_points)\n",
    "\n",
    "    return(popt, rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to fit a power-law with log-periodic corrections to data\n",
    "\"\"\"\n",
    "def lppl_fit(all_points, final_benioff, final_t):\n",
    "    #Define the log-periodic power-law and parameters\n",
    "    def lppl(x, omega, m, B, C, phi):\n",
    "        return B*x**m + (B*C*x**m)*np.cos(omega * np.log(x) + phi)\n",
    "    \n",
    "    #Set a starting point for the parameters\n",
    "    starting_point = [4.6,0.37, 8800000,-0.02, 4.08]\n",
    "    #Fit the data\n",
    "    popt, pcov = curve_fit(lppl, #function\n",
    "                           final_t - all_points.day_1900, #x\n",
    "                           final_benioff - all_points.Cummulative_Benioff_Strain, #A-e\n",
    "                           maxfev=10000,\n",
    "                           p0 = starting_point\n",
    "                          )\n",
    "    #Make predictions\n",
    "    pred = final_benioff - popt[2]*(final_t - all_points.day_1900)**popt[1] + \\\n",
    "    -popt[2]*popt[3]*(final_t - all_points.day_1900)**popt[1] \\\n",
    "    *np.cos(popt[0] * np.log((final_t - all_points.day_1900)) + popt[4])\n",
    "\n",
    "    #Calculate the rmse\n",
    "    rmse = rmse_calc(pred, all_points)\n",
    "    \n",
    "    return(popt, rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to plot the points and fitted lines\n",
    "\"\"\"\n",
    "def plot_fit(sub_points, target_point, sl_opt, pl_opt, lppl_opt, lppl = False, method = 'Bowman'):\n",
    "    \n",
    "    #Set up an x-range\n",
    "    x_range = range(sub_points.day_1900.min()-5,sub_points.day_1900.max()+5)\n",
    "    x_range2 = [target_point.final_t - e for e in x_range]\n",
    "    \n",
    "    #Make the predictions\n",
    "    sl_pred = sl_opt[0] + sl_opt[1]*x_range\n",
    "    pl_pred = target_point.final_benioff + pl_opt[0]*x_range2**pl_opt[1]\n",
    "    if(lppl):\n",
    "        lppl_pred = target_point.final_benioff - lppl_opt[2]*x_range2**lppl_opt[1] + \\\n",
    "        -lppl_opt[2]*lppl_opt[3]*x_range2**lppl_opt[1]*np.cos(lppl_opt[0] * np.log(x_range2) + lppl_opt[4])\n",
    "    \n",
    "    #Make the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    #Plot the cummulative Benioff strain\n",
    "    ax.plot(sub_points.day_1900/365, sub_points.Cummulative_Benioff_Strain, marker='o', ls = 'None')\n",
    "    #ax.set_xlim(sub_points.Time_Delta.max()/365 + 5, 0)  # decreasing time\n",
    "    ax.set_xlabel('Years since 1900')\n",
    "    ax.set_ylabel('Cumulative Benioff Strain (J^1/2)')\n",
    "    ax.set_title('%s Latlong (%.2f, %.2f), r = %dkm' % (target_point.Name,\n",
    "                                                        target_point.Latitude,\n",
    "                                                        target_point.Longitude,\n",
    "                                                        target_point.r))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    #Plot the fitted straight line and power law\n",
    "    x_range_plot = [e/365 for e in x_range]\n",
    "    ax.plot(x_range_plot, sl_pred, ls = '--', label='Straight-line fit')\n",
    "    ax.plot(x_range_plot, pl_pred, ls = '--', label='Power-law fit')\n",
    "    \n",
    "    ax.legend()\n",
    "    \n",
    "    #If required, plot the LPPL fit\n",
    "    if(lppl):\n",
    "        ax.plot(x_range_plot, lppl_pred, ls = '--', label='LPPL fit')\n",
    "        ax.legend()\n",
    "        plt.savefig('Fitted_Data/' + method + '/' + target_point.Name + '_' + str(round(target_point.r,0)) + '_lppl_fits.png')\n",
    "    else:\n",
    "        plt.savefig('Fitted_Data/' + method + '/' + target_point.Name + '_' + str(round(target_point.r,0)) + '_fits.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to plot the c-values (curvature parameter) from the Bowman method\n",
    "\"\"\"\n",
    "def c_plot(c_values, lat, lon, min_r, min_c, name, lppl = False, method = 'Bowman'):\n",
    "    #Plot the values\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(*zip(*c_values), marker = 'o')\n",
    "    ax.set_xlabel('Region radius (km)')\n",
    "    \n",
    "    #Set the title depending on whether C or C2 has been plotted\n",
    "    if(lppl):\n",
    "        ax.set_ylabel('C2 (lppl rmse / power-law rmse)')\n",
    "        ax.set_title('%s Latlong (%.2f, %.2f), C2 values' % (name, lat, lon))\n",
    "    else:\n",
    "        ax.set_ylabel('C (power-law rmse / straight-line rmse)')\n",
    "        ax.set_title('%s Latlong (%.2f, %.2f), C values' % (name, lat, lon))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    #Save out the plot\n",
    "    file_name = 'Fitted_Data/' + method + '/' + name\n",
    "    if(lppl):\n",
    "        plt.savefig(file_name +  '_lppl_c.png')\n",
    "    else:\n",
    "        plt.savefig(file_name +  '_c.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to plot the c-values (curvature parameter) from the Robinson method\n",
    "In this case we hold two values from the radius, lat delta and long delta steady\n",
    "and vary the third for the plot\n",
    "\"\"\"\n",
    "def c_plot_robinson(c_values, lat, lon, fixed_ref, name, lppl = False, method = 'Robinson'):\n",
    "    all_refs = ['Radius (km)', 'Lat (delta)', 'Long (delta)']\n",
    "    \n",
    "    #Find the two varying values\n",
    "    varying_refs = [e for e in all_refs if e != fixed_ref]\n",
    "    \n",
    "    #Plot the curvature parameter for the varying value\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(*zip(*c_values), marker = 'o')\n",
    "    ax.set_xlabel(fixed_ref)\n",
    "    \n",
    "    #Set the y-axis title and graph titile\n",
    "    if(lppl):\n",
    "        ax.set_ylabel('C2 (lppl rmse / power-law rmse)')\n",
    "        ax.set_title('%s, fixed %s and %s, varying %s, C2 values' % (name,\n",
    "                                                                     varying_refs[0],\n",
    "                                                                     varying_refs[1], fixed_ref))\n",
    "    else:\n",
    "        ax.set_ylabel('C (power-law rmse / straight-line rmse)')\n",
    "        ax.set_title('%s, varying %s, C values' % (name, fixed_ref))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    #Save out the plot\n",
    "    file_name = 'Fitted_Data/' + method + '/' + name\n",
    "    if(lppl):\n",
    "        plt.savefig(file_name + '_' + fixed_ref +  '_lppl_c.png')\n",
    "    else:\n",
    "        plt.savefig(file_name + '_' + fixed_ref +  '_c.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Master Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to fit the data using the different methods (straight-line and power-law)\n",
    "Returns the dataset used for the fit, the curvature parameter \n",
    "and the power law fitting parameters\n",
    "\"\"\"\n",
    "def fitting_function(target_point, df, r, lat_delta = 0, long_delta = 0,\n",
    "                     make_plot = False, return_data = False,\n",
    "                     method = 'Bowman', master_lppl = True):\n",
    "    \n",
    "    target_point['r'] = r\n",
    "    #Get the relevant earthquakes within the radius\n",
    "    sub_points = get_points(target_point, df, radius = r,\n",
    "                                        M_min = target_point.Magnitude - 2,\n",
    "                                        lat_delta = lat_delta, long_delta = long_delta)\n",
    "    \n",
    "    #Check if there are enough points to continue with the fit\n",
    "    if(sub_points.shape[0] < 10):\n",
    "        return\n",
    "\n",
    "    #Calculate the cummulative benioff strain\n",
    "    sub_points = benioff_calc(sub_points)\n",
    "    target_point['final_benioff'] = sub_points.iloc[sub_points.shape[0]-1].Cummulative_Benioff_Strain\n",
    "    target_point['final_t'] = sub_points.iloc[sub_points.shape[0]-1].day_1900\n",
    "\n",
    "    #Remove earthquakes on the final day from the table\n",
    "    sub_points = sub_points[sub_points.day_1900 < target_point['final_t']]\n",
    "\n",
    "    #sub_points.drop(sub_points.tail(1).index,inplace=True)\n",
    "    sub_points.index = sub_points.day_1900\n",
    "\n",
    "    #Check if there are enough points to continue with the fit\n",
    "    if(sub_points.shape[0] < 6):\n",
    "        return\n",
    "\n",
    "    #Fit to a straight line\n",
    "    sl_opt, sl_rmse = straight_line_fit(sub_points,\n",
    "                                        target_point['final_benioff'])\n",
    "\n",
    "    #Fit to a power law straight line\n",
    "    pl_opt, pl_rmse = power_law_fit(sub_points,\n",
    "                                    target_point['final_benioff'],\n",
    "                                    target_point['final_t'])\n",
    "    #Calculate C\n",
    "    c = pl_rmse/sl_rmse\n",
    "    \n",
    "    #If required, try fitting to the LPPL\n",
    "    if(master_lppl):\n",
    "        try:\n",
    "            #Fit to the lppl\n",
    "            lppl_opt, lppl_rmse = lppl_fit(sub_points,\n",
    "                                           target_point['final_benioff'],\n",
    "                                           target_point['final_t'])\n",
    "            c2 = lppl_rmse/pl_rmse\n",
    "        except:\n",
    "            lppl_opt = None\n",
    "            c2 = None\n",
    "            master_lppl = False\n",
    "    else:\n",
    "        lppl_opt = None\n",
    "        c2 = None\n",
    "        \n",
    "    #Plot the cummulative Benioff strain and the fitted lines if required\n",
    "    if(make_plot):\n",
    "        #Set the latitude and longitude used\n",
    "        target_point.Latitude = round(target_point.Latitude + lat_delta*180/pi,2)\n",
    "        target_point.Longitude = round(target_point.Longitude + long_delta*180/pi,2)\n",
    "        plot_fit(sub_points, target_point, sl_opt, pl_opt, lppl_opt, master_lppl, method)\n",
    "        \n",
    "    #If required, return the data used for the fit and the fitted parameters\n",
    "    if(return_data):\n",
    "        return(sub_points, sl_opt, pl_opt, lppl_opt)    \n",
    "    \n",
    "    return(r, c, c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Bowman Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loop through all key earthquakes and apply the Bowman method\n",
    "\"\"\"\n",
    "#Set up the dataframe to store results\n",
    "bowman_results = pd.DataFrame(columns=['id', 'bowman_r', 'bowman_c', 'bowman_r_lppl', 'bowman_c_lppl'])\n",
    "\n",
    "for i in range(0,key_earthquakes.shape[0]):\n",
    "    #Set the target point\n",
    "    target_point = key_earthquakes.iloc[i].copy()\n",
    "    name = target_point.Name\n",
    "    print(name)\n",
    "    print(\"Target Point lat, long, magnitude: (%f, %f, %f)\" % \\\n",
    "          (target_point.Latitude, target_point.Longitude, target_point.Magnitude))\n",
    "\n",
    "    c_values = []\n",
    "    c2_values = []\n",
    "    #Loop through the different radii\n",
    "    for r in np.arange(10, 1300, 10).tolist():\n",
    "        #Apply the master fitting function\n",
    "        result = fitting_function(target_point, df, r, make_plot = True)\n",
    "        if(result == None):\n",
    "            continue\n",
    "        r, c, c2 = result\n",
    "        #Store the resulting curvature parameters\n",
    "        c_values.append((r, c))\n",
    "        if(c2 != None):\n",
    "            c2_values.append((r, c2))\n",
    "     \n",
    "    if(len(c_values) == 0):\n",
    "        continue\n",
    "    #Find the radius at the optimum curvature parameter (C)\n",
    "    min_r, min_c = min(c_values, key = lambda t: t[1])\n",
    "    print(\"Minimum c value %.2f, occurs at a radius of %dkm\" % (min_c, min_r))\n",
    "    #Plot the variation in the curvature parameter with radius\n",
    "    c_plot(c_values, target_point.Latitude, target_point.Longitude, min_r,min_c, name)\n",
    "    \n",
    "    #Find the radius at the optimum curvature parameter (C2)\n",
    "    min_r_lppl, min_c_lppl = min(c2_values, key = lambda t: t[1])\n",
    "    print(\"Minimum c value lppl %.2f, occurs at a radius of %dkm\" % (min_c_lppl, min_r_lppl))\n",
    "    #Plot the variation in C2 with radius\n",
    "    c_plot(c2_values, target_point.Latitude, target_point.Longitude,\n",
    "       min_r_lppl,min_c_lppl, name, lppl = True)\n",
    "    \n",
    "    #Add to the results table\n",
    "    bowman_results = bowman_results.append({'id': target_point.event_id,\n",
    "                           'bowman_r': min_r,\n",
    "                           'bowman_c': min_c,\n",
    "                           'bowman_r_lppl': min_r_lppl,\n",
    "                           'bowman_c_lppl': min_c_lppl}, \n",
    "                          ignore_index=True)\n",
    "bowman_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save out the results\n",
    "bowman_results.to_csv('Fitted_Data/fitting_results_bowman_3.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Loop through all sample earthquakes using the Robinson method\n",
    "Use the Jaume and Sykes method to calculate R (critical region radius)\n",
    "Vary this by +/-25% in steps of 5%\n",
    "Vary the latlong by +/-0.5 degrees in steps of 0.1 degree \n",
    "\"\"\"\n",
    "#Set up a dataframe to store the results\n",
    "robinson_results = pd.DataFrame(columns=['id', 'robinson_r','robinson_lat_delta','robinson_long_delta',\n",
    "                                         'robinson_c', 'robinson_r_lppl',\n",
    "                                         'robinson_lat_delta_lppl','robinson_long_delta_lppl',\n",
    "                                         'robinson_c_lppl'])\n",
    "\n",
    "for i in range(0,key_earthquakes.shape[0]):\n",
    "    #Define the target point\n",
    "    target_point = key_earthquakes.iloc[i].copy()\n",
    "    name = target_point.Name\n",
    "    print(name)\n",
    "    print(\"Target Point lat, long, magnitude, radius: (%f, %f, %f, %f)\" % \\\n",
    "          (target_point.Latitude, target_point.Longitude, target_point.Magnitude, target_point.R_km))\n",
    "\n",
    "    c_values = []\n",
    "    c2_values = []\n",
    "\n",
    "    #Loop through all epicentres and radii\n",
    "    for r_delta in np.arange(-0.25, 0.25, 0.05):\n",
    "        r = (1 + r_delta)*target_point.R_km\n",
    "        for lat_delta in np.arange(-0.5, 0.6, 0.1).tolist():\n",
    "            lat_delta = np.round(lat_delta, 2)*pi/180\n",
    "            for long_delta in np.arange(-0.5, 0.6, 0.4).tolist():\n",
    "                long_delta = np.round(long_delta, 2)*pi/180\n",
    "\n",
    "                #Apply the master fitting function\n",
    "                result = fitting_function(target_point, df, r, lat_delta, long_delta, make_plot = True)\n",
    "                if(result == None):\n",
    "                    continue\n",
    "                r, c, c2 = result\n",
    "                #Store the resulting curvature parameters\n",
    "                c_values.append((r, lat_delta, long_delta, c))\n",
    "                if(c2 != None):\n",
    "                    c2_values.append((r, lat_delta, long_delta, c2))\n",
    "                \n",
    "    if(len(c_values) == 0):\n",
    "        continue\n",
    "\n",
    "    #Find r, lat delta and long delta values at the optimum curvature parameters\n",
    "    min_r, min_lat_delta, min_long_delta, min_c = min(c_values, key = lambda t: t[3])\n",
    "    min_r_lppl, min_lat_delta_lppl, min_long_delta_lppl, min_c_lppl = min(c2_values, key = lambda t: t[3])\n",
    "    print(\"Minimum c value %.2f, occurs at a radius of %dkm\" % (min_c, min_r))\n",
    "    print(\"Minimum c lppl value %.2f, occurs at a radius of %dkm\" % (min_c_lppl, min_r_lppl))\n",
    "    \n",
    "    #Plot the variation in C with r, lat and long - vary one at a time\n",
    "    fix_loc_c = [(e[0],e[3]) for e in c_values if (e[1] == min_lat_delta) & (e[2] == min_long_delta)]\n",
    "    fix_rlat_c = [(e[2],e[3]) for e in c_values if (e[1] == min_lat_delta) & (e[0] == min_r)]\n",
    "    fix_rlong_c = [(e[1],e[3]) for e in c_values if (e[0] == min_r) & (e[2] == min_long_delta)]\n",
    "    fix_loc_c_lppl = [(e[0],e[3]) for e in c2_values if (e[1] == min_lat_delta_lppl) & (e[2] == min_long_delta_lppl)]\n",
    "    fix_rlat_c_lppl = [(e[2],e[3]) for e in c2_values if (e[1] == min_lat_delta_lppl) & (e[0] == min_r_lppl)]\n",
    "    fix_rlong_c_lppl = [(e[1],e[3]) for e in c2_values if (e[0] == min_r_lppl) & (e[2] == min_long_delta_lppl)]\n",
    "    all_sub = [fix_loc_c, fix_rlat_c, fix_rlong_c, fix_loc_c_lppl, fix_rlat_c_lppl, fix_rlong_c_lppl]\n",
    "    all_ref = ['Radius (km)', 'Lat (delta)', 'Long (delta)',\n",
    "               'Radius (km)', 'Lat (delta)', 'Long (delta)']\n",
    "    \n",
    "    for i in [0,1,2]:\n",
    "        c_plot_robinson(all_sub[i], target_point.Latitude, target_point.Longitude, all_ref[i],\n",
    "                        name, lppl = False, method = 'Robinson')\n",
    "    for i in [3,4,5]:\n",
    "        c_plot_robinson(all_sub[i], target_point.Latitude, target_point.Longitude,all_ref[i],\n",
    "                        name, lppl = True, method = 'Robinson')\n",
    "    \n",
    "    #Add the results to the dataframe\n",
    "    robinson_results = robinson_results.append({'id': target_point.event_id,\n",
    "                                                'robinson_r': min_r,\n",
    "                                                'robinson_lat_delta': min_lat_delta,\n",
    "                                                'robinson_long_delta': min_long_delta,\n",
    "                                                'robinson_c': min_c,\n",
    "                                                'robinson_r_lppl': min_r_lppl,\n",
    "                                                'robinson_lat_delta_lppl': min_lat_delta_lppl,\n",
    "                                                'robinson_long_delta_lppl': min_long_delta_lppl,\n",
    "                                                'robinson_c_lppl': min_c_lppl}, \n",
    "                                               ignore_index=True)\n",
    "\n",
    "robinson_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save out the results\n",
    "robinson_results.to_csv('Fitted_Data/fitting_results_robinson_3.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the Results from both Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the tables and save out\n",
    "results = bowman_results.merge(robinson_results, how = 'left', on = 'id')\n",
    "results.to_csv('Fitted_Data/fitting_results_comparison_4.csv', index = False)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loop through all earthquakes in the results table\n",
    "Rerun the fit for the optimum radius, lat and long\n",
    "Save out the fit graphs and the parameters\n",
    "\"\"\"\n",
    "#Set up a dataframe to store the results\n",
    "results2 = pd.DataFrame(columns = list(results.columns) + ['bowman_pl_m', 'bowman_pl_B',\n",
    "                                                           'bowman_lppl_m','bowman_lppl_B',\n",
    "                                                           'bowman_lppl_omega', 'bowman_lppl_C',\n",
    "                                                           'bowman_lppl_phi',\n",
    "                                                          'robinson_pl_m', 'robinson_pl_B',\n",
    "                                                           'robinson_lppl_m','robinson_lppl_B',\n",
    "                                                           'robinson_lppl_omega', 'robinson_lppl_C',\n",
    "                                                          'robinson_lppl_phi'])\n",
    "\n",
    "#Loop through all earthquakes\n",
    "for i in range(0,results.shape[0]):\n",
    "    #Define the target point\n",
    "    target_point = key_earthquakes[key_earthquakes.event_id == results.id.iloc[i]].iloc[0]\n",
    "    name = target_point.Name\n",
    "    print(name)\n",
    "    print(\"Target Point lat, long, magnitude, radius: (%f, %f, %f, %f)\" % \\\n",
    "          (target_point.Latitude, target_point.Longitude, target_point.Magnitude, target_point.R_km))\n",
    "    \n",
    "    #Run the fitting for Bowman\n",
    "    bowman_fit = fitting_function(target_point, df, results.bowman_r.iloc[i],\n",
    "                                  make_plot = True, return_data = True,\n",
    "                                  method = \"Bowman\", master_lppl = False)\n",
    "    \n",
    "    #Run the fitting for Robinson\n",
    "    robinson_fit = fitting_function(target_point, df, results.robinson_r.iloc[i],\n",
    "                                    results.robinson_lat_delta.iloc[i],\n",
    "                                    results.robinson_long_delta.iloc[i],\n",
    "                                   make_plot = True, return_data = True,\n",
    "                                    method = \"Robinson\", master_lppl = False)\n",
    "    \n",
    "    #Run the fitting for Bowman - LPPL\n",
    "    bowman_fit_lppl = fitting_function(target_point, df, results.bowman_r_lppl.iloc[i],\n",
    "                                  make_plot = True, return_data = True,\n",
    "                                  method = \"Bowman\", master_lppl = True)\n",
    "    \n",
    "    #Run the fitting for Robinson - LPPL\n",
    "    robinson_fit_lppl = fitting_function(target_point, df, results.robinson_r_lppl.iloc[i],\n",
    "                                    results.robinson_lat_delta_lppl.iloc[i],\n",
    "                                    results.robinson_long_delta_lppl.iloc[i],\n",
    "                                   make_plot = True, return_data = True,\n",
    "                                    method = \"Robinson\", master_lppl = True)\n",
    "    \n",
    "    #Add the fitted parameters to the table    \n",
    "    results_dict = dict(results.iloc[i])\n",
    "    results_dict['bowman_pl_m'] = bowman_fit[2][1]\n",
    "    results_dict['bowman_pl_B'] = bowman_fit[2][0]\n",
    "    results_dict['bowman_lppl_m'] = bowman_fit_lppl[3][1]\n",
    "    results_dict['bowman_lppl_B'] = -bowman_fit_lppl[3][2]\n",
    "    results_dict['bowman_lppl_omega'] = bowman_fit_lppl[3][0]\n",
    "    results_dict['bowman_lppl_C'] = bowman_fit_lppl[3][3]\n",
    "    results_dict['bowman_lppl_phi'] = bowman_fit_lppl[3][4]\n",
    "    \n",
    "    if(robinson_fit != None):\n",
    "        results_dict['robinson_pl_m'] = robinson_fit[2][1]\n",
    "        results_dict['robinson_pl_B'] = robinson_fit[2][0]\n",
    "        results_dict['robinson_lppl_m'] = robinson_fit_lppl[3][1]\n",
    "        results_dict['robinson_lppl_B'] = -robinson_fit_lppl[3][2]\n",
    "        results_dict['robinson_lppl_omega'] = robinson_fit_lppl[3][0]\n",
    "        results_dict['robinson_lppl_C'] = robinson_fit_lppl[3][3]\n",
    "        results_dict['robinson_lppl_phi'] = robinson_fit_lppl[3][4]\n",
    "    \n",
    "    results2 = results2.append(results_dict, ignore_index=True)\n",
    "results2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the optimum values/parameters table with the original dataset\n",
    "final_results = df.merge(results2, how = 'inner', left_on = 'event_id', right_on = 'id')\n",
    "final_results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format the dataframe \n",
    "final_results_formatted = final_results.copy()\n",
    "final_results_formatted.drop(['MagType','event_id', 'year', 'year_1900',\n",
    "                              'day_1900', 'Energy_log10','Energy', 'R_log10',\n",
    "                             'lat_rad', 'lon_rad', 'id','robinson_r_lppl',\n",
    "                             'robinson_lppl_B','robinson_lat_delta_lppl',\n",
    "                             'robinson_long_delta_lppl', 'robinson_c_lppl',\n",
    "                             'robinson_lppl_m', 'robinson_lppl_B', 'robinson_lppl_omega',\n",
    "                              'robinson_lppl_C', 'robinson_lppl_phi'],\n",
    "                             axis = 1, inplace = True)\n",
    "final_results_formatted = final_results_formatted.round(2)\n",
    "\n",
    "final_results_formatted[['R_km', 'bowman_r', 'bowman_r_lppl',\n",
    "                         'robinson_r','bowman_pl_B','bowman_lppl_B',\n",
    "                         'robinson_pl_B']] = \\\n",
    "                final_results_formatted[['R_km', 'bowman_r', 'bowman_r_lppl',\n",
    "                                         'robinson_r','bowman_pl_B','bowman_lppl_B',\n",
    "                                        'robinson_pl_B']].fillna(0.0).astype(int)\n",
    "    \n",
    "final_results_formatted.columns = ['Date', 'Lat', 'Long', 'Mag', 'Name', 'Paper',\n",
    "                                   'Calculated R (km)','bowman_r', 'bowman_c',\n",
    "                                   'bowman_r_lppl', 'bowman_c_lppl','robinson_r',\n",
    "                                   'robinson_lat_delta', 'robinson_long_delta', 'robinson_c',\n",
    "                                   'bowman_pl_m',\n",
    "                                   'bowman_pl_B', 'bowman_lppl_m', 'bowman_lppl_B',\n",
    "                                   'bowman_lppl_omega','bowman_lppl_C', 'bowman_lppl_phi',\n",
    "                                   'robinson_pl_m', 'robinson_pl_B']\n",
    "\n",
    "#Rearrange the columns\n",
    "final_results_formatted = final_results_formatted[['Date', 'Lat', 'Long', 'Mag', 'Name', 'Paper',\n",
    "                            'Calculated R (km)','bowman_r','robinson_r', 'bowman_c',\n",
    "                            'robinson_c','bowman_pl_m','robinson_pl_m','bowman_pl_B',\n",
    "                            'robinson_pl_B','robinson_lat_delta', 'robinson_long_delta',\n",
    "                            'bowman_r_lppl', 'bowman_c_lppl','bowman_lppl_m', 'bowman_lppl_B',\n",
    "                            'bowman_lppl_omega','bowman_lppl_C', 'bowman_lppl_phi']]\n",
    "final_results_formatted.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save out the final results table\n",
    "final_results_formatted.to_csv('Fitted_Data/formatted_results_2.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
